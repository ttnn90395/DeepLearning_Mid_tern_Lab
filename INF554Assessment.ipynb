{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF554 Assessment: FCNN, Transformers and Representation Learning\n",
    "\n",
    "In this assessment, you will delve deeper into the training of Fully-Connected Neural Networks (FCNNs) and Transformers, and explore the representations learned by the models and their efficiency.\n",
    "\n",
    "**Important notice:**\n",
    "1. You must submit a single file YOUR-NAME__your-surname.ipynb by **<span style=\"color:red\">Monday November 3rd at 14:00 CET on Moodle</span>**.\n",
    "   - Make sure to submit a couple of hours before the deadline to avoid technical difficulties causing you to miss it.\n",
    "   - Late submissions will not be accepted.\n",
    "2. Please note that this assessment is **to be completed individually**.\n",
    "   - Detected cases of plagiarism will be reported to the university, which in serious cases can have far-reaching consequences.\n",
    "   - Make sure to submit your own, original solutions. \n",
    "3. You should implement what you are asked to, where you are asked to, and only use the external libraries that are already imported.\n",
    "   - You will not receive marks for importing functions you are asked to implement, unless specifically stated.\n",
    "   - You should only modify the parts of the notebook marked as questions, and delimited with `## Question xx: insert your code here <...> ## End-of-code: Question xx`\n",
    "   - Adding intermediate computation cells, changing the execution order, or modifying the cells producing visual outputs is prohibited.\n",
    "\n",
    "This assessment consists of two independent parts. The first focuses on FFNs and Transformers trained to compute the modulo of integers represented as binary strings. The second focuses on pre-trained Transformers fine-tuned for a classification task on real data.\n",
    "\n",
    "**Grading scale**\n",
    "\n",
    "```markdown\n",
    "- Part 1 [34 points]\n",
    "  - Q1 [CODE]:   2 points\n",
    "  - Q2 [CODE]:   5 points\n",
    "  - Q3 [CODE]:   5 points\n",
    "  - Q4 [THEORY]: 2 points\n",
    "  - Q5 [THEORY]: 2 points\n",
    "  - Q6 [THEORY]: 2 points\n",
    "  - Q7 [CODE]:   4 points\n",
    "  - Q8 [THEORY]: 3 points\n",
    "  - Q9 [THEORY]: 3 points\n",
    "  - Q10[THEORY]: 6 points\n",
    "- Part 2 [16 points]\n",
    "  - Q11[CODE]:   4 points\n",
    "  - Q12[CODE]:   5 points\n",
    "  - Q13[THEORY]: 7 points\n",
    "\n",
    "TOTAL: 50 points (25 for theory and 25 for code)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 0 - Setup\n",
    "\n",
    "This notebook must be executed with **Python 3.12**, using the requirements provided with the course. If your installation is correct, you should not need to modify this part. In any case, we remind you that you are not allowed to use additional libraries as replacements for the code you are asked to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from scipy import special as scp\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be executed with either CPU, CUDA GPU, or Apple MPS. The runtime is longer on CPU but should remain manageable (around 5-10 minutes max on a recent mid-range processor for the longest code block). Moreover, the qualitative observations you are asked to comment on in the theory questions are the same for any device.\n",
    "\n",
    "**Important note:**  \n",
    "If you encounter issues with your device and wish to force your code to run on the CPU only, you must:  \n",
    "1. Uncomment the last line of this code block to declare the `DEVICE` variable.  \n",
    "2. Replace `accelerate.Accelerator()` with `accelerate.Accelerator(device_placement=False)` in Part 2.  \n",
    "\n",
    "You do **not** need to do this if your laptop has no compatible device, as the CPU is used by default in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "def clear_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if torch.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "# Uncomment to force CPU-only\n",
    "# DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_hash(sample: str, len=3) -> str:\n",
    "    return base64.urlsafe_b64encode(hashlib.md5(sample.encode(\"utf-8\")).digest()).decode()[:len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: FCNNs and Transformers learning modulo division on binary strings\n",
    "\n",
    "In this part, we will train two model architectures: Fully Connected Neural Networks and Transformers. Our models will be trained to compute the modulo of integers represented as binary strings. The strings will have a fixed length of 20 bits. The number used as the modulus for the computations is called the BASE. For a fixed value of BASE, the problem becomes a classification task with BASE possible labels.\n",
    "\n",
    "For example, if we compute modulo BASE=2, labels are integers in $[0,1]$:\n",
    "\n",
    "$$00000000000000000101 \\rightarrow  1 \\quad [5\\%2=1]$$\n",
    "$$00000000000000101010 \\rightarrow  0 \\quad [42\\%2=0]$$\n",
    "$$01110000110110000011 \\rightarrow  1 \\quad [462211\\%2=1]$$\n",
    "\n",
    "For example, if we compute modulo BASE=3, labels are integers in $[0,2]$:\n",
    "\n",
    "$$00000000000000000101 \\rightarrow  2 \\quad [5\\%3=2]$$\n",
    "$$00000000000000101010 \\rightarrow  0 \\quad [42\\%3=0]$$\n",
    "$$01110000110110000011 \\rightarrow  1 \\quad [462211\\%3=1]$$\n",
    "\n",
    "For example, if we compute modulo BASE=128, labels are integers in $[0,127]$:\n",
    "\n",
    "$$00000000000000000101 \\rightarrow  5 \\quad [5\\%128=5]$$\n",
    "$$00000000000000101010 \\rightarrow  42 \\quad [42\\%128=42]$$\n",
    "$$01110000110110000011 \\rightarrow  3 \\quad [462211\\%128=3]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-A: Dataset\n",
    "\n",
    "Our task is extremely simple from an arithmetical point of view. Consequently, we can easily generate synthetic data. **Our datasets will consist of lists of strings of length 20 containing only \"0\" and \"1\" characters.** The labels (the result of the modulo computation) can be easily computed and will be generated on the fly during training, without needing to save them in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 20\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [CODE] Question 1 (2 points)\n",
    "\n",
    "Implement `get_sample_bin` and `get_sample_label` functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_bin(sample: int) -> str:\n",
    "    \"\"\"\n",
    "    Computes the binary representation of an integer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample : int\n",
    "        The integer to be represented as a binary string. Must be less than 2**SEQ_LEN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string of length exactly SEQ_LEN containing \"0\" and \"1\" characters, representing\n",
    "        the binary representation of `sample`.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Question 1: insert your code here\n",
    "\n",
    "    ...\n",
    "    \n",
    "    ## End-of-code: Question 1\n",
    "\n",
    "def get_sample_label(sample: str, base: int) -> int:\n",
    "    \"\"\"\n",
    "    Computes the label for a binary string sample given a modulus.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample : str\n",
    "        Binary string representing an integer.\n",
    "    base : int\n",
    "        The modulus to compute the label.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label : int\n",
    "        The result of converting `sample` to an integer and taking modulo `base`.\n",
    "    \"\"\"\n",
    "    ## Question 1: insert your code here\n",
    "\n",
    "    ...\n",
    "\n",
    "    ## End-of-code: Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    ds_size: int, seed: int = 42, test_prop: float = 1/8\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset of binary strings and splits it into training and test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_size : int\n",
    "        The total number of samples to generate.\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility (default is 42).\n",
    "    test_prop : float, optional\n",
    "        Proportion of the dataset to use as the test set (default is 1/8).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_set : list of str\n",
    "        List of binary strings to be used for training.\n",
    "    test_set : list of str\n",
    "        List of binary strings to be used for testing.\n",
    "    \"\"\"\n",
    "    rg = np.random.RandomState(seed)\n",
    "    candidate_pool = np.array(np.arange(1 << SEQ_LEN), dtype=int)\n",
    "    rg.shuffle(candidate_pool)\n",
    "    selected_samples = candidate_pool[:ds_size]\n",
    "    full_dataset = [get_sample_bin(sample) for sample in selected_samples]\n",
    "    cut_idx = int(len(full_dataset) * (1 - test_prop))\n",
    "    return full_dataset[:cut_idx], full_dataset[cut_idx:]\n",
    "\n",
    "\n",
    "def get_labels(dataset: list[str], base: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Computes the labels for a dataset of binary string samples given a modulus.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list of str\n",
    "        List of binary strings representing integers.\n",
    "    base : int\n",
    "        The modulus to compute the labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list of int\n",
    "        List of integers where each element is the result of converting the corresponding\n",
    "        binary string in `dataset` to an integer and taking modulo `base`.\n",
    "    \"\"\"\n",
    "    return [get_sample_label(item, base) for item in dataset]\n",
    "\n",
    "\n",
    "def batch_to_tensor(batch: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a batch of binary strings into a PyTorch tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : list of str\n",
    "        List of binary strings, each representing an integer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : torch.Tensor\n",
    "        A tensor of shape (batch_size, SEQ_LEN), containing the binary values of the strings.\n",
    "    \"\"\"\n",
    "    result = [[int(char) for char in s] for s in batch]\n",
    "    return torch.tensor(result, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY\n",
    "ds_train, ds_test = get_dataset(1 << 16)\n",
    "print(f\"Sample 0 hash: {safe_hash(ds_train[0])}\")\n",
    "print(f\"Label 0 hash: {safe_hash(str(get_sample_label(ds_train[0], base=1024)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1-B : FCNN implementation and training\n",
    "\n",
    "We will now implement Fully-Connected Neural Networks to solve the classification problem described above, and train them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_parameter_sizes(model: torch.nn.Module) -> str:\n",
    "    \"\"\"\n",
    "    Returns a summary of the parameters in a PyTorch model, including the number\n",
    "    of parameter groups, and the total number of parameters.\"\"\"\n",
    "    \n",
    "    param_list = list(model.parameters())\n",
    "    result = f\"Number of parameter groups: {len(param_list)}\\n\"\n",
    "    result += ('-' * 55) + \"\\n\"\n",
    "\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        result += f\"{name:25} : [{param.numel():6}] {tuple(param.size())}\\n\"\n",
    "        total_params += param.numel()\n",
    "\n",
    "    result += f\"{'TOTAL':25} : [{total_params:6}]\\n\"\n",
    "    result += ('-' * 55) + \"\\n\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [CODE] Question 2 (5 points)\n",
    "\n",
    "Implement the `FCNN` class below. This class allows you to instantiate fully connected neural networks (FCNNs) of various sizes. \n",
    "\n",
    "- The `hidden_dim` parameter refers to the hidden dimension of the *intermediate* layers. If it is `None`, there are no intermediate hidden layers, resulting in a single classification layer directly connecting the input to the output.\n",
    "- The `num_layers` parameter specifies the number of layers *before* the final classification layer. For example, with `num_layers=1`, there is a first linear layer mapping the input to a hidden space, followed by a classification layer mapping the hidden space to the output. Moreover, `num_layers=0` should be equivalent to `hidden_dim=None`.\n",
    "\n",
    "*Hint: you need to append instances of `nn.Module` subclasses in `layers` list, in the right order. These instances should correspond to the component of the model: linear layers and activation functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully Connected Neural Network (FCNN) for classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hidden_dim : int or None\n",
    "        Dimension of the intermediate hidden layers. If None, the network\n",
    "        has no hidden layers and consists of a single linear classification layer.\n",
    "    base : int\n",
    "        Number of output classes.\n",
    "    num_layers : int, default=1\n",
    "        Number of hidden layers before the final classification layer.\n",
    "        Equivalent to hidden_dim=None if num_layers=0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int | None, base: int, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        ## Question 2: insert your code here\n",
    "        ## You should populate `layer` with the layers needed, in the right order\n",
    "\n",
    "        ...\n",
    "\n",
    "        ## End-of-code: Question 2\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY - you should have 19458 parameters in total\n",
    "print(check_model_parameter_sizes(FCNN(hidden_dim=128, base=2, num_layers=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY - you should have 63 parameters in total\n",
    "print(check_model_parameter_sizes(FCNN(hidden_dim=128, base=3, num_layers=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-C: Training loop\n",
    "\n",
    "We will now implement the training loop and evaluate our models on our synthetic datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [CODE] Question 3 (5 points)\n",
    "\n",
    "Implement the `eval_model` function below.\n",
    "\n",
    "*Hint: if your implementation is correct, the output of the next cell should be very close to 0.5 because it's evaluating the accuracy of untrained models for a binary classification task.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: nn.Module, ds_test: list[str], labels_test: list[int], batch_size: int = 256, \n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluates a classification model on a test dataset and computes accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The PyTorch model to evaluate.\n",
    "    ds_test : list of str\n",
    "        List of binary string samples for testing.\n",
    "    labels_test : list of int\n",
    "        List of integer labels corresponding to `ds_test`.\n",
    "    batch_size : int, optional\n",
    "        Number of samples per batch for evaluation (default is 256).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : float\n",
    "        Fraction of correctly classified samples in the test set.\n",
    "    \"\"\"\n",
    "    ## Question 3: insert your code here\n",
    "    \n",
    "    ...\n",
    "\n",
    "    ## End-of-code: Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY\n",
    "accuracies = []\n",
    "_, ds_test = get_dataset(1 << 8, test_prop=1)\n",
    "test_base = 2\n",
    "for _ in range(1 << 10):\n",
    "    model = FCNN(None, test_base).to(DEVICE)\n",
    "    accuracies.append(eval_model(model, ds_test, get_labels(ds_test, test_base)))\n",
    "\n",
    "print(f\"Average accuracy: {sum(accuracies) / len(accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide the already-implemented training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    base: int,\n",
    "    ds_train: list[str],\n",
    "    ds_test: list[str],\n",
    "    labels_train: list[int] | None = None,\n",
    "    labels_test: list[int] | None = None,\n",
    "    eval_step: int | None = None,\n",
    "    batch_size: int = 256,\n",
    "    silent: bool = False,\n",
    "    optimizer: torch.optim.Optimizer | None = None,\n",
    ") -> tuple[list[float], list[float], list[float], list[int]]:\n",
    "    \"\"\"\n",
    "    Trains a classification model on a binary string dataset and evaluates performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The PyTorch model to train.\n",
    "    base : int\n",
    "        The modulus used to compute labels from binary strings.\n",
    "    ds_train : list of str\n",
    "        Training dataset of binary strings.\n",
    "    ds_test : list of str\n",
    "        Test dataset of binary strings.\n",
    "    labels_train : list of int, optional\n",
    "        Precomputed labels for `ds_train`. If None, labels are computed on the fly.\n",
    "    labels_test : list of int, optional\n",
    "        Precomputed labels for `ds_test`. If None, labels are computed on the fly.\n",
    "    eval_step : int, optional\n",
    "        Evaluate the model every `eval_step` steps. If None, set automatically.\n",
    "    batch_size : int, optional\n",
    "        Number of samples per batch (default is 256).\n",
    "    silent : bool, optional\n",
    "        If True, disables progress printing (default is False).\n",
    "    optimizer : torch.optim.Optimizer, optional\n",
    "        Optimizer to use for training. If None, SGD with lr=0.01 and momentum=0.5 is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss : list of float\n",
    "        List of training loss values recorded at evaluation steps.\n",
    "    train_acc : list of float\n",
    "        List of training accuracies recorded at evaluation steps.\n",
    "    test_acc : list of float\n",
    "        List of test accuracies recorded at evaluation steps.\n",
    "    num_samples : list of int\n",
    "        Cumulative number of samples processed at each evaluation step.\n",
    "    \"\"\"\n",
    "    if eval_step is None:\n",
    "        eval_step = np.ceil(len(ds_train) // batch_size)\n",
    "    if eval_step == 0:\n",
    "        eval_step = 1\n",
    "\n",
    "    model.train()\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    # Labels?\n",
    "    if labels_train is None:\n",
    "        labels_train = get_labels(ds_train, base=base)\n",
    "    if labels_test is None:\n",
    "        labels_test = get_labels(ds_test, base=base)\n",
    "\n",
    "    # Results\n",
    "    loss_cache, acc_cache = [], []\n",
    "    train_loss, train_acc, test_acc, num_samples = [], [], [], []\n",
    "\n",
    "    # Loop\n",
    "    sample_count = 0\n",
    "    step = 0\n",
    "    for i in tqdm(range(0, len(ds_train), batch_size), disable=silent):\n",
    "        batch_samples = ds_train[i : i + batch_size]\n",
    "        batch_labels = labels_train[i : i + batch_size]\n",
    "\n",
    "        bits = batch_to_tensor(batch_samples)\n",
    "        targets = torch.tensor(batch_labels, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(bits).cpu()\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Caching\n",
    "        loss_cache.extend([loss.item()] * bits.size(0))\n",
    "        acc_cache.extend((output.argmax(dim=1) == targets).detach().cpu().int())\n",
    "        sample_count += bits.size(0)\n",
    "\n",
    "        # Evaluating?\n",
    "        step += 1\n",
    "        if (step % eval_step == 0) or (step - 1 == len(ds_train) // batch_size):\n",
    "            train_loss.append(sum(loss_cache) / len(loss_cache))\n",
    "            train_acc.append(sum(acc_cache) / len(acc_cache))\n",
    "            test_acc.append(eval_model(model, ds_test, labels_test))\n",
    "            num_samples.append(sample_count)\n",
    "            loss_cache, acc_cache = [], []\n",
    "\n",
    "            if not silent:\n",
    "                print(\n",
    "                    f\"[STEP:{step:3} - SAMPLES:{sample_count:5} | Train loss {train_loss[-1]:.4f} | Train acc {train_acc[-1]:.4f} | Test acc {test_acc[-1]:.4f}\"\n",
    "                )\n",
    "\n",
    "    # Output\n",
    "    return train_loss, train_acc, test_acc, num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D: Impact of BASE\n",
    "\n",
    "We will now evaluate the impact of several hyperparameters on the performance of the model throughout training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perfs_and_times(\n",
    "        perfs: dict[int, tuple[list[int], list[float]]],\n",
    "        times: dict[int, float],\n",
    "        hpar_name: str,\n",
    "        all_hpar_values: list[float],\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Plot test accuracy and computation time for different hyperparameter values.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax_perf, ax_time = ax[0], ax[1]\n",
    "\n",
    "    # Plot performance curves\n",
    "    for hpar in all_hpar_values:\n",
    "        ax_perf.plot(perfs[hpar][0], perfs[hpar][1], label=f\"{hpar_name}={hpar}\")\n",
    "\n",
    "    ax_perf.set_xlabel(\"Dataset size\")\n",
    "    ax_perf.set_ylabel(\"Test accuracy\")\n",
    "    ax_perf.legend()\n",
    "    ax_perf.set_title(f\"Performance depending on {hpar_name}\")\n",
    "\n",
    "    # Plot computation times as evenly spaced bar chart\n",
    "    if times is None:\n",
    "        ax_time.set_axis_off()\n",
    "    else:\n",
    "        comp_times = [times[hpar] for hpar in all_hpar_values]\n",
    "\n",
    "        x = range(len(all_hpar_values))  # evenly spaced positions\n",
    "        ax_time.bar(x, comp_times)\n",
    "\n",
    "        ax_time.set_xlabel(hpar_name)\n",
    "        ax_time.set_ylabel(\"Time (s)\")\n",
    "        ax_time.set_title(f\"Computation time depending on {hpar_name}\")\n",
    "        ax_time.set_xticks(x)\n",
    "        ax_time.set_xticklabels(all_hpar_values)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loops in the next computation cell and answer:\n",
    "\n",
    "#### [THEORY] Question 4 (2 points)\n",
    "\n",
    "1. For which values of **BASE** does the model clearly outperform random performance? What do these values have in common?  \n",
    "   - <span style=\"color:green\">Your one-line answer here</span>  \n",
    "2. What family of **BASE** values appears learnable within a reasonable time, and why is it expected that these are easier to learn than others?  \n",
    "   - <span style=\"color:green\">Your two-line answer here</span>\n",
    "\n",
    "#### [THEORY] Question 5 (2 points)\n",
    "Compare the performance with 10000 samples at BASE=16 and the performance with 20000 samples at BASE=32. Explain the ratio you observed.\n",
    "- <span style=\"color:green\">Your two-lines answer here</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_BASES = [2, 3, 4, 5, 8, 16, 32, 128]\n",
    "DS_SIZE = 1<<15\n",
    "HIDDEN_DIM = None\n",
    "NUM_LAYERS = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "perfs = {}\n",
    "times: dict[int, float] = {}\n",
    "\n",
    "for base in tqdm(ALL_BASES):\n",
    "    ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "    model = FCNN(hidden_dim=HIDDEN_DIM, base=base, num_layers=NUM_LAYERS).to(\n",
    "        DEVICE\n",
    "    )\n",
    "    t_start = time()\n",
    "    train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "        model,\n",
    "        ds_train=ds_train,\n",
    "        ds_test=ds_test,\n",
    "        base=base,\n",
    "        silent=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "    )\n",
    "    t_stop = time()\n",
    "    perfs[base] = (num_samples, test_acc)\n",
    "    times[base] = t_stop - t_start\n",
    "\n",
    "plot_perfs_and_times(perfs, times, \"BASE\", ALL_BASES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-E: Impact of the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loops in the next computation cell and answer:\n",
    "\n",
    "#### [Theory] Question 6 (2 points)\n",
    "\n",
    "Justify why the choice of batch size involves a trade-off, and explain why this trade-off is even more salient with GPU accelerators.\n",
    "- <span style=\"color:green\">Your two-lines answer here</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 32\n",
    "DS_SIZE = 1<<15\n",
    "HIDDEN_DIM = None\n",
    "NUM_LAYERS = 3\n",
    "ALL_BATCH_SIZES = [1, 2, 4, 6, 16, 32, 64]\n",
    "\n",
    "perfs: dict[int, tuple[list[int], list[float]]] = {}\n",
    "times: dict[int, float] = {}\n",
    "\n",
    "for batch_size in tqdm(ALL_BATCH_SIZES):\n",
    "\n",
    "    ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "    model = FCNN(hidden_dim=HIDDEN_DIM, base=BASE, num_layers=NUM_LAYERS).to(\n",
    "        DEVICE\n",
    "    )\n",
    "    t_start = time()\n",
    "    train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "        model,\n",
    "        ds_train=ds_train,\n",
    "        ds_test=ds_test,\n",
    "        base=BASE,\n",
    "        silent=True,\n",
    "        batch_size=batch_size,\n",
    "        eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "    )\n",
    "    t_stop = time()\n",
    "    perfs[batch_size] = (num_samples, test_acc)\n",
    "    times[batch_size] = t_stop - t_start\n",
    "\n",
    "plot_perfs_and_times(perfs, times, \"Batch size\", ALL_BATCH_SIZES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now re-examine the trade-off involved in choosing the batch size, but in a more realistic setting. In the previous setup, the labels were \"perfect\" because they were defined by a deterministic mathematical rule. In real-world scenarios, however, labels are noisy and may even contradict each other. To approximate this situation, we will introduce label noise: a fraction `noise_prop` of the labels in the training set (but **not** in the test set) will be randomly replaced with values uniformly sampled from `[0, BASE-1]`.\n",
    "\n",
    "#### [CODE] Question 7 (4 points)\n",
    "\n",
    "Implement the new version of `get_labels`. You MUST use a `np.random.RandomState` to ensure that the injected noise is deterministic and fully replicable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataset: list[str], base: int, noise_prop: float = 0.0) -> list[int]:\n",
    "    \"\"\"\n",
    "    Computes labels for a dataset of binary string samples with optional label noise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list of str\n",
    "        List of binary strings representing integers.\n",
    "    base : int\n",
    "        The modulus to compute the labels.\n",
    "    noise_prop : float, optional\n",
    "        Proportion of labels in the dataset to replace with random values \n",
    "        uniformly sampled from [0, base-1]. Default is 0.0 (no noise).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list of int\n",
    "        List of integer labels corresponding to the dataset, possibly with noise injected.\n",
    "    \"\"\"\n",
    "    ## Question 7: insert your code here\n",
    "    \n",
    "    ...\n",
    "\n",
    "    ## End-of-code: Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY\n",
    "size = 1<<10\n",
    "_, ds_test = get_dataset(size, seed=42, test_prop=1)\n",
    "labels_no_noise = np.array(get_labels(ds_test, base=SEQ_LEN, noise_prop=0))\n",
    "labels_noise_1 = np.array(get_labels(ds_test, base=SEQ_LEN, noise_prop=.05))\n",
    "labels_noise_2 = np.array(get_labels(ds_test, base=SEQ_LEN, noise_prop=.05))\n",
    "\n",
    "print(f\"Approximate lower bound on noise ratio: {sum(labels_no_noise != labels_noise_1) / size:.2%}\")\n",
    "print(f\"Replicability ratio: {sum(labels_noise_1 == labels_noise_2) / size:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loops in the next computation cell and answer:\n",
    "\n",
    "#### [THEORY] Question 8 (3 points)\n",
    "\n",
    "Explain why, in the presence of noisy labels, the final performance is non-monotonic with respect to the batch size (3 points, one for your explanation in each regime: low, intermediate a high batch size).\n",
    "- <span style=\"color:green\">Low batch size: ...</span>\n",
    "- <span style=\"color:green\">Middle batch size: ...</span>\n",
    "- <span style=\"color:green\">Hich batch size: ...</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 32\n",
    "DS_SIZE = 1<<16\n",
    "HIDDEN_DIM = None\n",
    "NUM_LAYERS = 3\n",
    "NOISE_PROP = 0.7\n",
    "ALL_BATCH_SIZES = [1, 2, 4, 6, 16, 32, 64]\n",
    "\n",
    "perfs = {}\n",
    "times = {}\n",
    "\n",
    "for batch_size in tqdm(ALL_BATCH_SIZES):\n",
    "    ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "    labels_train = get_labels(ds_train, base=BASE, noise_prop=NOISE_PROP)\n",
    "    labels_test = get_labels(ds_test, base=BASE, noise_prop=0.0)\n",
    "    model = FCNN(hidden_dim=HIDDEN_DIM, base=BASE, num_layers=NUM_LAYERS).to(\n",
    "        DEVICE\n",
    "    )\n",
    "    t_start = time()\n",
    "    train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "        model,\n",
    "        ds_train=ds_train,\n",
    "        ds_test=ds_test,\n",
    "        base=BASE,\n",
    "        labels_train=labels_train,\n",
    "        labels_test=labels_test,\n",
    "        silent=True,\n",
    "        batch_size=batch_size,\n",
    "        eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "    )\n",
    "    t_stop = time()\n",
    "    perfs[batch_size] = (num_samples, test_acc)\n",
    "    times[batch_size] = t_stop - t_start\n",
    "\n",
    "plot_perfs_and_times(perfs, times, \"Batch size\", ALL_BATCH_SIZES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-F: Introducing transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the next cells, we observe that scaling the hidden dimension is generally more effective than increasing the number of layers. However, empirically, deeper models have been shown to be effective for learning complex representations and multi-step tasks. In practice, modern LLMs include dozens of layers that progressively refine the representation of samples (see PART 2). We will now study Transformers, which are the basic building blocks of modern LLMs. We will train them on the same tasks and compare them with FCNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 32\n",
    "DS_SIZE = 1<<16\n",
    "ALL_HIDDEN_DIM = [4, 8, 16, 32, 64, 128]\n",
    "NUM_LAYERS = 1\n",
    "NOISE_PROP = 0.0\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "perfs = {}\n",
    "times = {}\n",
    "\n",
    "for hiddent_dim in tqdm(ALL_HIDDEN_DIM):\n",
    "        ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "        model = FCNN(hidden_dim=hiddent_dim, base=BASE, num_layers=NUM_LAYERS).to(\n",
    "            DEVICE\n",
    "        )\n",
    "        t_start = time()\n",
    "        train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "            model,\n",
    "            ds_train=ds_train,\n",
    "            ds_test=ds_test,\n",
    "            base=BASE,\n",
    "            silent=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "        )\n",
    "        t_stop = time()\n",
    "        perfs[hiddent_dim] = (num_samples, test_acc)\n",
    "        times[hiddent_dim] = t_stop - t_start\n",
    "\n",
    "plot_perfs_and_times(perfs, times, \"Hidden dim\", ALL_HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 32\n",
    "DS_SIZE = 1<<16\n",
    "HIDDEN_DIM = 64\n",
    "ALL_LAYERS = [1, 2, 4, 8, 16]\n",
    "NOISE_PROP = 0.0\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "perfs = {}\n",
    "times = {}\n",
    "\n",
    "for layer in tqdm(ALL_LAYERS):\n",
    "        ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "        model = FCNN(hidden_dim=HIDDEN_DIM, base=BASE, num_layers=layer).to(\n",
    "            DEVICE\n",
    "        )\n",
    "        t_start = time()\n",
    "        train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "            model,\n",
    "            ds_train=ds_train,\n",
    "            ds_test=ds_test,\n",
    "            base=BASE,\n",
    "            silent=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "        )\n",
    "        t_stop = time()\n",
    "        perfs[layer] = (num_samples, test_acc)\n",
    "        times[layer] = t_stop - t_start\n",
    "\n",
    "plot_perfs_and_times(perfs, times, \"Num of layers\", ALL_LAYERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a naive implementation of Transformers, that does not include any positional encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuloTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        num_layers: int,\n",
    "        base: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bit_embed = nn.Embedding(2, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, base)\n",
    "\n",
    "    def forward(self, bits: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        bits: LongTensor of shape [batch, seq_len] with values in {0,1}\n",
    "        returns: logits [batch, base]\n",
    "        \"\"\"\n",
    "        emb = self.bit_embed(bits.long())           # [B, L, D]\n",
    "        enc = self.encoder(emb)                     # [B, L, D]\n",
    "        pooled = enc.mean(dim=1)                    # [B, D] (simple mean pooling)\n",
    "        return self.classifier(pooled)              # [B, base]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer architecture relies on the attention formula (see the original paper [1]). Consider a sequence of $N \\in \\mathbb{N}$ tokens. Let $x \\in \\mathbb{R}^{N, d_x}$ be the stacked representation of each token before the attention module. We define three matrices which are computed from three learned parameters tensors $W_Q, W_K, W_V$: the learned queries, keys and values:\n",
    "\n",
    "$$\n",
    "Q = x W_Q \\in \\mathbb{R}^{N \\times d_k} \\\\\n",
    "K = x W_K \\in \\mathbb{R}^{N \\times d_k} \\\\\n",
    "V = x W_V \\in \\mathbb{R}^{N \\times d_v} \\\\\n",
    "$$\n",
    "\n",
    "The representation of tokens at layer $l$ is updated using $y$ defined as follows:\n",
    "\n",
    "$$\n",
    "y = \\text{Attention}(Q, K, V) = \\text{softmax}\\!\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "[1] A. Vasawani, N. Shazeer, N. Parmar, J. Uszkoreit et al. *Attention is all you need*. NIPS. 2017. https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [THEORY] Question 9 (3 points)\n",
    "\n",
    "Let $P \\in \\mathbb{R}^{d_x, d_x}$ be a permutation matrix: if $\\sigma: \\llbracket 0, N-1 \\rrbracket \\mapsto \\llbracket 0, N-1 \\rrbracket$ is a (bijective) permutation, then $P$ contains only zeros, except ones at indices $(\\sigma(k), k)$ for $k \\in \\llbracket 0, N-1 \\rrbracket$. Then, let $x_P = Px$ be the permuted input representations.\n",
    "\n",
    "What is the impact of this permutation of the tokens in the input string on the output of the attention mechanism as defined above? Back up your answer with a mathematical demonstration.\n",
    "\n",
    "Do you think that the observed impact affects the performance of our implemented transformer in our task positively or negatively?\n",
    " \n",
    "<span style=\"color:green\">Insert your proof here</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [THEORY] Question 10 (6 points)\n",
    "\n",
    "What is the theoreticaly optimal accuracy of the model in the training cell above? Derive it matematically. Your demonstration should produce a closed-form expression that you must implement in **one** line of Python in the dedicated spot in the next cell. Its approximate value is $0.58$. In your mathematical demonstration, denote the binomial coefficient \"$k$ among $n$\" as $Binom(n,k)$.\n",
    "\n",
    "<span style=\"color:green\">Insert your proof here</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_line_closed_form_value = 0.58 # Question 10: Replace \"0.58\" with your single-line close-formed expression\n",
    "\n",
    "print(f\"Theoretical limit: {one_line_closed_form_value:.8f} [hash: {safe_hash(str(one_line_closed_form_value)[:8])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 2\n",
    "DS_SIZE = 1<<16\n",
    "BATCH_SIZE = 16\n",
    "ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "model = ModuloTransformer(d_model=64, nhead=4, num_layers=2, base=BASE).to(DEVICE)\n",
    "train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "        model,\n",
    "        ds_train=ds_train,\n",
    "        ds_test=ds_test,\n",
    "        base=BASE,\n",
    "        silent=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-G: Positional encoding (Pedagogical only, no questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the model to capture the order of tokens in a sequence, we add positional encoding to the token embeddings. These encodings assign each position a unique vector that can be interpreted by the model. A common choice is the sinusoidal positional encoding, which uses sine and cosine functions at different frequencies so that relative positions can be represented without learning additional parameters.\n",
    "\n",
    "The sinusoidal positional encoding is defined as follows. For a sequence of length $N$ and embedding dimension $d_v$:  \n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i)}   = \\sin\\!\\left(\\frac{pos}{10000^{\\frac{2i}{d_v}}}\\right)\n",
    "$$\n",
    "$$\n",
    "PE_{(pos, 2i+1)} = \\cos\\!\\left(\\frac{pos}{10000^{\\frac{2i}{d_v}}}\\right)\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $pos \\in [0, L-1]$ is the token position,  \n",
    "- $i$ is the dimension index.  \n",
    "\n",
    "We provide an implementation below. It returns a tensor of shape $(L, d_v)$. The training in the next cells should reach perfect test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_pe(d_model: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute sinusoidal positional encodings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        Dimensionality of the embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pe : torch.Tensor of shape (SEQ_LEN, d_model)\n",
    "        Positional encoding matrix, where even dimensions use sine and odd\n",
    "        dimensions use cosine.\n",
    "    \"\"\"\n",
    "    pos = torch.arange(SEQ_LEN, dtype=torch.float32).unsqueeze(1)            # Shape [L, 1]\n",
    "    i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)              # Shape [1, D]\n",
    "    angle_rates = 1.0 / torch.pow(10000.0, (2 * (i // 2)) / d_model)         # Shape [1, D]\n",
    "    angles = pos * angle_rates                                               # Shape [L, D]\n",
    "    pe = torch.zeros(SEQ_LEN, d_model)\n",
    "    pe[:, 0::2] = torch.sin(angles[:, 0::2])\n",
    "    pe[:, 1::2] = torch.cos(angles[:, 1::2])\n",
    "    return pe  # Shape [L, D]\n",
    "\n",
    "plt.imshow(sinusoidal_pe(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuloTransformerWithPE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        num_layers: int,\n",
    "        base: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bit_embed = nn.Embedding(2, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pe = sinusoidal_pe(d_model).unsqueeze(0).to(DEVICE) # [1, L, D]\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, base)\n",
    "\n",
    "    def add_positional(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, L, D = x.shape\n",
    "        return x + self.pe[:, :L, :]\n",
    "\n",
    "    def forward(self, bits: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        bits: LongTensor of shape [batch, seq_len] with values in {0,1}\n",
    "        returns: logits [batch, base]\n",
    "        \"\"\"\n",
    "        emb = self.bit_embed(bits.long())           # [B, L, D]\n",
    "        emb = self.add_positional(emb)              # [B, L, D]\n",
    "        enc = self.encoder(emb)                     # [B, L, D]\n",
    "        pooled = enc.mean(dim=1)                    # [B, D] (simple mean pooling)\n",
    "        return self.classifier(pooled)              # [B, base]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 32\n",
    "DS_SIZE = 1<<16\n",
    "BATCH_SIZE = 16\n",
    "ds_train, ds_test = get_dataset(ds_size=DS_SIZE)\n",
    "model = ModuloTransformerWithPE(d_model=64, nhead=4, num_layers=2, base=BASE).to(DEVICE)\n",
    "train_loss, train_acc, test_acc, num_samples = train_model(\n",
    "    model,\n",
    "    ds_train=ds_train,\n",
    "    ds_test=ds_test,\n",
    "    base=BASE,\n",
    "    silent=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    eval_step=DS_SIZE // BATCH_SIZE // 32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Real Data\n",
    "\n",
    "In the previous part, we observed that the *representation* of integers as binary strings affected the tasks the model could perform (see your answer to Question 4). More generally, learning useful and efficient representations is crucial for models to succeed. In this part, we will explore the representations learned by real LLMs and how they support task performance.\n",
    "\n",
    "### Dataset and model\n",
    "\n",
    "We study Pythia models [2] fine-tuned on the AGNews dataset. This dataset consists of news snippets categorized into four classes: **0=World**, **1=Sport**, **2=Business**, and **3=Sci/Tech**. The task is to predict the class from the text snippet alone.\n",
    "\n",
    "We fine-tuned a Pythia-160M model on this dataset using the Next Token Prediction (NTP) task. The fine-tuning script is provided in  `training_pythia.py`. We used a template to prompt the model to classify the news snippet. The latest token of each sample contains the label predicted by the model. Consequently, the logits of the penultimate token of the sequence play a similar role to the classification logits in the latest layers of the FCNNs trained in Part 1. These logits are used to compute the loss and train the model for classification. The next cells display a few dataset samples.\n",
    "\n",
    "### Overview of the approach\n",
    "\n",
    "This part of the assignment is loosely based on recent work in mechanistic interpretability [3]. This paper explores new methods to extracts some concepts from the internal representations of LLMs. For example, in Pythia models fine-tuned on AGNews, a sample may be classified as **World** if the hidden states represent concepts like *politics*, *war*, or *election*, or as **Sport** if they represent concepts like *goal*, *match*, or *competition*. In [3], Variational Autoencoders (VAEs) are trained to uncover directions in hidden space that correspond to such concepts, offering interpretable explanations for LLM predictions.\n",
    "\n",
    "In this assignment, we adopt a simpler approach. Instead of training VAEs, we apply Principal Component Analysis (PCA) directly to the hidden representations. This allows us to visualize how the model represents samples from different classes across layers and training checkpoints.\n",
    "\n",
    "- [2] S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley et al. *Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling*. ArXiv preprint. 2023. https://arxiv.org/abs/2304.01373\n",
    "- [3] M. Le Bail, J. Dentan, D. Buscaldi, and S. Vanier. *Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders.* ArXiv preprint. 2025. https://arxiv.org/abs/2506.23951\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To force CPU-only, replace with accelerate.Accelerator(device_placement=False)\n",
    "accelerator = accelerate.Accelerator()\n",
    "DATASET_NAME = \"fancyzhx/ag_news\"\n",
    "MODEL_NAME = \"EleutherAI/pythia-160m\"\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "dataset[\"test\"].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide checkpoints of models that have already been fine-tuned. The following cell creates a DataLoader, `test_dl`, which will be used to explore the representations learned by the model at different checkpoints. This DataLoader is similar to the one used during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side=\"left\"\n",
    "\n",
    "def format_template(sample):\n",
    "    return dict(\n",
    "        text = f\"What type of information is presented in this article?\\n\\n{sample['text']}\\n\\nOPTIONS:\\n0: World\\n1: Sport\\n2 :Buisiness\\n3: Sci/Tech\\nANSWER:{sample['label']}\",\n",
    "        label=sample['label'],\n",
    "    )\n",
    "\n",
    "tokenized_ds_test = dataset[\"test\"].map(format_template).map(lambda sample: tokenizer(sample[\"text\"]))\n",
    "tokenized_ds_test = tokenized_ds_test.select(np.random.RandomState(42).choice(len(tokenized_ds_test), size=1000, replace=False))\n",
    "\n",
    "test_dl = accelerator.prepare(DataLoader(\n",
    "    tokenized_ds_test.select_columns([\"input_ids\", \"attention_mask\", \"label\"]),\n",
    "    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False),\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [CODE] Question 11 (4 points)\n",
    "\n",
    "Implement the evaluation loop. We recall that we use Next Token Prediction task. The label must be extracted consistently with the template used for prediction, and the index of the logits should be chosen accordingly. See the introduction of Part 2 for details. The loss should be computed using `torch.nn.CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: nn.Module, eval_dl: DataLoader) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a Transformer model on a dataset loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The Transformer model to evaluate.\n",
    "    eval_dl : DataLoader\n",
    "        A PyTorch DataLoader providing batches of evaluation data, with input\n",
    "        features and labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : float\n",
    "        Fraction of correctly predicted labels over the dataset.\n",
    "    avg_loss : float\n",
    "        Mean cross-entropy loss computed on the predicted labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    for batch in tqdm(eval_dl):\n",
    "        outputs = model(**batch)\n",
    "        outputs_logits = outputs.logits\n",
    "\n",
    "        # Retrieving logits and labels\n",
    "        ## Question 11: your code here\n",
    "        idx_logits = ...\n",
    "        idx_labels = ...\n",
    "        ## End-of-code: Question 11\n",
    "        logits_prediction = outputs_logits[:,idx_logits].contiguous().view(-1, model.config.vocab_size)\n",
    "        labels_to_pred = batch.labels[:,idx_labels].view(-1)\n",
    "        \n",
    "        ## Question 11: your code here\n",
    "        \n",
    "        ...\n",
    "\n",
    "        ## End-of-code: Question 11\n",
    "        \n",
    "\n",
    "    return (correct / total, np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate the five fine-tuning checkpoints that we provide: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CHECKPOINTS = [50,100,200,1000,3000]\n",
    "ALL_LAYERS = [1,3,5,7,9,11]\n",
    "MODEL_PYTHIA=\"jdentan/teaching-pythia160m-AGNews-chk{checkpoint}\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "for checkpoint in ALL_CHECKPOINTS:\n",
    "    clear_cache()\n",
    "    current_model = AutoModelForCausalLM.from_pretrained(MODEL_PYTHIA.format(checkpoint=checkpoint)).to(DEVICE)\n",
    "    eval_results.append(eval_model(current_model, test_dl))\n",
    "    clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "ax.plot(ALL_CHECKPOINTS, [result[0].cpu() for result in eval_results], label=\"accuracy\")\n",
    "ax.plot(ALL_CHECKPOINTS, [result[1] for result in eval_results], label=\"loss\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Accuracy / Loss\")\n",
    "ax.set_title(\"Training Pythia 160m on AG News\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representations across time and layers\n",
    "\n",
    "We will now extract the representations learned by the models during fine-tuning.\n",
    "\n",
    "#### [CODE] Question 12 (5 points)\n",
    "\n",
    "Complete the implementation of the function below. The label must be extracted consistently with the template used for prediction, and the representations should be taken at the token index used to compute the logits for label prediction. See the introduction of Part 2 for details.  \n",
    "\n",
    "\n",
    "Hint: using kwarg `output_hidden_states=True` in model(...) allows you to access `outputs[\"hidden_states\"][layer]`, for each layer, which is a tensor of shape `(batch_size, sequence_length, hidden_dimension)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representations(\n",
    "    model: nn.Module, eval_dl: DataLoader\n",
    ") -> tuple[dict[int, torch.Tensor], torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Extract hidden representations from all layers of a Transformer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The Transformer model from which to extract hidden states.\n",
    "    eval_dl : DataLoader\n",
    "        A PyTorch DataLoader providing batches of input samples and labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_repz_tensor : dict[int, torch.Tensor]\n",
    "        A dictionary mapping layer indices to tensors of shape (num_samples, hidden_dim)\n",
    "        containing the hidden representations for each layer.\n",
    "    all_labels_tensor : torch.Tensor\n",
    "        Tensor of shape (num_samples,) containing the labels corresponding to the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Question 12: your code here\n",
    "    \n",
    "    ...\n",
    "\n",
    "    ## End-of-code: Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this function to load the representations learnt by the models at the five checkpoints we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_per_checkpoint = {}\n",
    "for checkpoint in ALL_CHECKPOINTS:\n",
    "    clear_cache()\n",
    "    current_model = AutoModelForCausalLM.from_pretrained(MODEL_PYTHIA.format(checkpoint=checkpoint)).to(DEVICE)\n",
    "    representations_per_checkpoint[checkpoint] = get_representations(current_model, test_dl)\n",
    "    clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row = len(ALL_LAYERS)\n",
    "n_col = len(ALL_CHECKPOINTS)\n",
    "fig, axs = plt.subplots(n_row, n_col, figsize=(4*n_col, 4*n_row))\n",
    "\n",
    "for idx_row, layer in enumerate(sorted(ALL_LAYERS, reverse=True)):\n",
    "    for idx_col, checkpoint in enumerate(ALL_CHECKPOINTS):\n",
    "        ax = axs[idx_row, idx_col]\n",
    "\n",
    "        # Fetching data\n",
    "        representations = representations_per_checkpoint[checkpoint][0][layer].cpu().numpy()\n",
    "        labels = representations_per_checkpoint[checkpoint][1].cpu().numpy()\n",
    "\n",
    "        # Reduce to 2D with PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        representations_2d = pca.fit_transform(representations)\n",
    "\n",
    "        ax.scatter(representations_2d[:,0], representations_2d[:,1], c=labels, cmap=\"tab10\", alpha=.7)\n",
    "        ax.set_title(f\"Checkpoint:{checkpoint} | Layer:{layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the previous cell and answer:\n",
    "\n",
    "#### [THEORY] Question 13 (7 points)\n",
    "\n",
    "Comment on the plot:  \n",
    "\n",
    "1. [2 points] What is the geometric shape underlying what we observe at **layer 11, checkpoint 3000**? What would you expect with a 3D PCA, and how can this be explained theoretically?\n",
    "   - <span style=\"color:green\">Your two-line answer here</span>\n",
    "\n",
    "2. [1 point] How does this **geometric shape** evolves at a fixed layer as training progresses? \n",
    "   - <span style=\"color:green\">Your one-line answer here</span>\n",
    "\n",
    "3. [1 points] How do the representations evolve across layers at a **fixed training step**?\n",
    "   - <span style=\"color:green\">Your one-line answer here</span>\n",
    "\n",
    "4. [3 points] Comment on how the **range of the values** shown on the axes at layer 11 evolves during training. Explain how the training process leads to this evolution.\n",
    "   - <span style=\"color:green\">Your concise answer here</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf554",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
